# Credit Card Fraud Detection ğŸ›¡ï¸ğŸ’³  

## ğŸ“Œ Descrizione del progetto  
Questo progetto ha come obiettivo lâ€™analisi e il rilevamento di transazioni fraudolente con carte di credito.  
Il dataset contiene oltre **280.000 transazioni** effettuate in due giorni, di cui circa **0.17% sono frodi**.  

ğŸ¯ Obiettivi principali:  
- Effettuare **analisi esplorativa (EDA)** per comprendere il dataset.  
- Applicare **tecniche di preprocessing** e **modelli di Machine Learning** per rilevare le frodi.  
- Valutare le performance del modello con metriche appropriate (Precision, Recall, F1-score, ROC AUC).  

---

## ğŸ“‚ Dataset  
Il dataset contiene 31 colonne:  

- **Time** â†’ tempo trascorso dalla prima transazione registrata.  
- **V1 â€¦ V28** â†’ variabili ottenute tramite PCA (componenti principali), non interpretabili direttamente.  
- **Amount** â†’ importo della transazione.  
- **Class** â†’ variabile target (0 = transazione legittima, 1 = frode).  

---

## ğŸ” Analisi Esplorativa (EDA) svolta finora  

âœ… Caricamento dataset con `pandas`  
âœ… Analisi generale con `info()`, `describe()` e `value_counts()` sulla colonna target `Class`  
âœ… Verifica valori nulli (`isnull().sum()`)  
âœ… Visualizzazione distribuzione della variabile target  
âœ… Creazione di una feature derivata da `Time` (**ora del giorno**)  
âœ… Barplot della **percentuale di frodi per ora del giorno** con `matplotlib` e `seaborn`  

ğŸ“Š *Esempio: percentuale di frodi per ora*  

```python
plt.figure(figsize=(14, 6))
sns.barplot(data=fraud_pct_df,
            x='hour_of_day',
            y='fraud_pct',
            color='steelblue')
plt.xlabel('Ora del giorno')
plt.ylabel('Percentuale di frodi (%)')
plt.title('Percentuale di frodi per ora')
plt.xticks(range(24))
plt.tight_layout()
plt.show()
ğŸš§ Work in Progress

Le prossime fasi in programma:

Analisi delle correlazioni tra le variabili

Preprocessing (scaling, bilanciamento, train/test split)

Addestramento modelli (es. Logistic Regression, Random Forest)

Valutazione con metriche di classificazione

Creazione README completo con risultati e osservazioni finali

ğŸ› ï¸ Tecnologie utilizzate

Python (Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn)

Jupyter Notebook
ğŸš§ Work in Progress

Le prossime fasi in programma:

Analisi delle correlazioni tra le variabili

Preprocessing (scaling, bilanciamento, train/test split)

Addestramento modelli (es. Logistic Regression, Random Forest)

Valutazione con metriche di classificazione

Creazione README completo con risultati e osservazioni finali

ğŸ› ï¸ Tecnologie utilizzate

Python (Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn)

Jupyter Notebook
